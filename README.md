# üèéÔ∏è F1 Race Prediction System Using VAE and Neural Networks

An advanced machine learning system for predicting Formula 1 race outcomes using **Variational Autoencoders (VAE)** and **Neural Networks** trained on latent space representations. The system leverages historical F1 data, circuit-specific characteristics, and engineered features to generate accurate race predictions.

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)
[![FastF1](https://img.shields.io/badge/FastF1-3.0+-green.svg)](https://github.com/theOehrly/Fast-F1)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)

---

## üìã Table of Contents

- [Overview](#-overview)
- [Key Features](#-key-features)
- [System Architecture](#-system-architecture)
- [Project Structure](#-project-structure)
- [Installation](#-installation)
- [Usage](#-usage)
- [Notebooks](#-notebooks)
- [Model Details](#-model-details)
- [Data Pipeline](#-data-pipeline)
- [Circuit Configuration](#-circuit-configuration)
- [Results](#-results)
- [Requirements](#-requirements)
- [Contributing](#-contributing)
- [License](#-license)

---

## üéØ Overview

This project implements a sophisticated F1 race prediction system that combines multiple machine learning approaches:

1. **VAE (Variational Autoencoder)**: Compresses 29 engineered features into a 4-dimensional latent space
2. **Neural Network Regressor**: Trained on the VAE latent space for position prediction (1-20)
3. **Position Categorization**: Discrete classification into racing categories (Podium/Points/Midfield/Backmarker)
4. **Bayesian Networks**: Probabilistic modeling on discretized latent space for uncertainty quantification
5. **Circuit-Specific Modeling**: Incorporates track characteristics, overtaking difficulty, and strategy factors
6. **Intelligent Data Collection**: Weighted historical data based on circuit similarity and recency

The system predicts race finishing positions based on:
- Starting grid position
- Qualifying performance
- Driver skill ratings
- Team strength metrics
- Circuit-specific factors
- Historical performance patterns

**Prediction Modes**:
- **Continuous**: Exact position prediction (1-20) using Neural Networks
- **Categorical**: Position category prediction (Podium/Points/Midfield/Backmarker) using Bayesian Networks with probability distributions

---

## ‚ú® Key Features

### üß† Advanced Machine Learning
- **Variational Autoencoder**: 29D ‚Üí 4D latent space compression with position prediction
- **Neural Network Regressor**: Dedicated model trained on latent representations
- **Bayesian Networks**: Probabilistic position category prediction with uncertainty quantification
- **Dual Architecture**: Combines VAE's generative capabilities with NN's predictive power and BN's probabilistic reasoning

### üèÅ Circuit Intelligence
- **23 F1 Circuits**: Comprehensive configuration for all tracks
- **Circuit-Specific Factors**: Grid importance, strategy impact, overtaking difficulty
- **Track Categories**: Street circuits, permanent tracks, semi-permanent venues
- **Chaos Modeling**: Circuit-specific unpredictability factors

### üìä Feature Engineering
- **Weighted Features**: Importance-based feature selection (high/medium/supporting)
- **29 Engineered Features**: Grid position, qualifying gaps, driver ratings, team strength
- **Temporal Weighting**: Recent races weighted more heavily than historical data
- **Circuit Similarity**: Similar tracks contribute more to prediction models

### üé® Comprehensive Visualization
- Latent space representations (UMAP/t-SNE)
- Training metrics and loss curves
- Prediction accuracy plots
- Feature importance analysis

---

## üèóÔ∏è System Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    F1 Prediction Pipeline                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

1. Data Collection (Notebook 01)
   ‚îú‚îÄ‚îÄ FastF1 API Integration
   ‚îú‚îÄ‚îÄ Multi-year historical data
   ‚îú‚îÄ‚îÄ Circuit-specific weighting
   ‚îî‚îÄ‚îÄ Temporal relevance scoring
           ‚Üì
2. Data Analysis (Notebook 02)
   ‚îú‚îÄ‚îÄ Statistical exploration
   ‚îú‚îÄ‚îÄ Feature distributions
   ‚îú‚îÄ‚îÄ Correlation analysis
   ‚îî‚îÄ‚îÄ Data quality validation
           ‚Üì
3. Preprocessing (Notebook 03)
   ‚îú‚îÄ‚îÄ Feature engineering (29 features)
   ‚îú‚îÄ‚îÄ Standardization & normalization
   ‚îú‚îÄ‚îÄ Missing value imputation
   ‚îî‚îÄ‚îÄ Train/validation splits
           ‚Üì
4. VAE Training (Notebook 04)
   ‚îú‚îÄ‚îÄ 29D ‚Üí 4D latent compression
   ‚îú‚îÄ‚îÄ Position prediction head
   ‚îú‚îÄ‚îÄ KL divergence regularization
   ‚îî‚îÄ‚îÄ Model checkpointing
           ‚Üì
5. Neural Network Training (Notebook 08)
   ‚îú‚îÄ‚îÄ Load VAE latent vectors
   ‚îú‚îÄ‚îÄ Train regression model (4D ‚Üí Position)
   ‚îú‚îÄ‚îÄ Hyperparameter optimization
   ‚îî‚îÄ‚îÄ Performance evaluation
           ‚Üì
6. Position Categorization & BN (Notebook 09)
   ‚îú‚îÄ‚îÄ Discretize positions into categories
   ‚îú‚îÄ‚îÄ Discretize 4D latent space into bins
   ‚îú‚îÄ‚îÄ Build Bayesian Network structure
   ‚îú‚îÄ‚îÄ Learn conditional probabilities (CPTs)
   ‚îî‚îÄ‚îÄ Generate probabilistic predictions
           ‚Üì
7. Predictions & Visualization
   ‚îú‚îÄ‚îÄ Race outcome forecasting
   ‚îú‚îÄ‚îÄ Confidence intervals
   ‚îú‚îÄ‚îÄ Feature importance
   ‚îî‚îÄ‚îÄ Model interpretability
```

---

## üìÅ Project Structure

```
f1_final/
‚îÇ
‚îú‚îÄ‚îÄ üìì Notebooks (Execution Order)
‚îÇ   ‚îú‚îÄ‚îÄ 01_data_collection.ipynb          # FastF1 data collection & weighting
‚îÇ   ‚îú‚îÄ‚îÄ 02_data_analysis.ipynb            # Exploratory data analysis
‚îÇ   ‚îú‚îÄ‚îÄ 03_preprocessing.ipynb            # Feature engineering & scaling
‚îÇ   ‚îú‚îÄ‚îÄ 04_vae_OPTIMIZED.ipynb           # VAE training & latent space creation
‚îÇ   ‚îú‚îÄ‚îÄ 08_latent_space_neural_net.ipynb # Neural network training on latent space
‚îÇ   ‚îî‚îÄ‚îÄ 09_bayesian_network_on_latent.ipynb # Position categorization & probabilistic BN
‚îÇ
‚îú‚îÄ‚îÄ üîß Configuration
‚îÇ   ‚îú‚îÄ‚îÄ config.py                         # Circuit configs, feature weights, settings
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt                  # Python dependencies
‚îÇ
‚îú‚îÄ‚îÄ üìä Data Directories
‚îÇ   ‚îú‚îÄ‚îÄ data/raw/                         # Raw FastF1 race data
‚îÇ   ‚îú‚îÄ‚îÄ data/processed/                   # Cleaned & weighted datasets
‚îÇ   ‚îú‚îÄ‚îÄ data/preprocessed/                # Engineered features & train/val splits
‚îÇ   ‚îî‚îÄ‚îÄ data/vae_results/                 # VAE predictions & latent vectors
‚îÇ
‚îú‚îÄ‚îÄ ü§ñ Models
‚îÇ   ‚îú‚îÄ‚îÄ models/*.pth                      # Trained VAE model checkpoints
‚îÇ   ‚îî‚îÄ‚îÄ models/*.json                     # Training summaries & metadata
‚îÇ
‚îú‚îÄ‚îÄ üíæ Cache
‚îÇ   ‚îî‚îÄ‚îÄ cache/                            # FastF1 session cache
‚îÇ
‚îú‚îÄ‚îÄ üìà Outputs
‚îÇ   ‚îú‚îÄ‚îÄ umap.png                          # Latent space visualization
‚îÇ   ‚îî‚îÄ‚îÄ *.png, *.json                     # Prediction plots & results
‚îÇ
‚îî‚îÄ‚îÄ üìö Documentation
    ‚îú‚îÄ‚îÄ README.md                         # This file
    ‚îú‚îÄ‚îÄ FEATURE_WEIGHTING_SUMMARY.md      # Feature importance details
    ‚îî‚îÄ‚îÄ PROJECT_OVERVIEW.md               # High-level project description
```

---

## üöÄ Installation

### Prerequisites

- Python 3.8 or higher
- pip package manager
- 4GB+ RAM recommended
- Internet connection (for FastF1 data fetching)

### Step 1: Clone the Repository

```bash
git clone https://github.com/HXMAN76/F1-Prediction-System-Using-VAE-and-BN.git
cd F1-Prediction-System-Using-VAE-and-BN
```

### Step 2: Install Dependencies

```bash
pip install -r requirements.txt
```

### Step 3: Verify Installation

```python
import fastf1
import torch
import pandas as pd
print(f"FastF1: {fastf1.__version__}")
print(f"PyTorch: {torch.__version__}")
print(f"CUDA Available: {torch.cuda.is_available()}")
```

---

## üíª Usage

### Quick Start: Run All Notebooks in Sequence

1. **Data Collection**
   ```bash
   jupyter notebook 01_data_collection.ipynb
   ```
   - Set `TARGET_CIRCUIT` (e.g., "Singapore", "Monaco", "Italy")
   - Run all cells to fetch and weight F1 data

2. **Data Analysis**
   ```bash
   jupyter notebook 02_data_analysis.ipynb
   ```
   - Explore feature distributions and correlations
   - Validate data quality

3. **Preprocessing**
   ```bash
   jupyter notebook 03_preprocessing.ipynb
   ```
   - Engineer 29 prediction features
   - Create train/validation splits

4. **VAE Training**
   ```bash
   jupyter notebook 04_vae_OPTIMIZED.ipynb
   ```
   - Train VAE (29D ‚Üí 4D latent space)
   - Generate latent vectors for all samples

5. **Neural Network Training (Notebook 08)**
   ```bash
   jupyter notebook 08_latent_space_neural_net.ipynb
   ```
   - Train regression model on latent space
   - Evaluate prediction accuracy

6. **Position Categorization & Bayesian Network (Notebook 09)**
   ```bash
   jupyter notebook 09_bayesian_network_on_latent.ipynb
   ```
   - Discretize positions into categories (Podium, Points, Midfield, Backmarker)
   - Build Bayesian Network on discretized latent space
   - Generate probabilistic position predictions with confidence scores

### Prediction for a New Circuit

```python
# In 01_data_collection.ipynb
TARGET_CIRCUIT = "Monaco"  # Change to any supported circuit
TARGET_YEAR = 2025

# Run all notebooks in sequence...
```

### Supported Circuits

All 23 current F1 calendar circuits are supported:
- **Street Circuits**: Monaco, Singapore, Saudi Arabia, Miami, Las Vegas, etc.
- **Permanent Tracks**: Monza, Spa, Silverstone, Suzuka, etc.
- **Semi-Permanent**: Canada, Australia, Mexico, etc.

See `config.py` ‚Üí `TRACK_CONFIGS` for the complete list.

---

## üìì Notebooks

### 01_data_collection.ipynb
**Purpose**: Fetch and prepare F1 race data  
**Key Functions**:
- FastF1 API integration
- Multi-year historical data collection (2019-2025)
- Circuit-specific data weighting
- Temporal relevance scoring (recent races weighted higher)
- Similar circuit identification (street/permanent/semi-permanent)

**Outputs**:
- `data/raw/f1_race_data_weighted_*.csv`

---

### 02_data_analysis.ipynb
**Purpose**: Exploratory data analysis and validation  
**Key Functions**:
- Statistical summaries (mean, median, std dev)
- Feature distribution analysis
- Correlation heatmaps
- Target variable (finishing position) analysis
- Data quality checks (missing values, outliers)

**Outputs**:
- Visualization plots
- Data quality reports

---

### 03_preprocessing.ipynb
**Purpose**: Feature engineering and data preparation  
**Key Functions**:
- Engineer 29 predictive features:
  - `grid_pos`: Starting grid position
  - `quali_pos`: Qualifying position
  - `driver_skill`: Historical driver rating
  - `team_strength`: Team performance metric
  - `gap_to_pole`: Qualifying time gap to pole
  - `pit_stops`: Number of pit stops
  - And 23 more engineered features...
- Feature scaling (StandardScaler)
- Train/validation split (80/20)
- Missing value imputation

**Outputs**:
- `data/preprocessed/f1_preprocessed_*.csv`
- Feature scaler objects (`.pkl`)

---

### 04_vae_OPTIMIZED.ipynb
**Purpose**: Train Variational Autoencoder for latent space compression  
**Architecture**:
- **Encoder**: 29D ‚Üí 128D ‚Üí 64D ‚Üí 4D (latent)
- **Decoder**: 4D ‚Üí 64D ‚Üí 128D ‚Üí 29D (reconstruction)
- **Position Predictor**: 4D ‚Üí 64D ‚Üí 32D ‚Üí 1 (position 1-20)

**Training Details**:
- Loss: Reconstruction + KL Divergence + Position Prediction
- Optimizer: Adam (lr=0.001)
- Epochs: 200-500 with early stopping
- Batch size: 32
- KL warmup: Gradual Œ≤ increase to 0.3
- Regularization: Dropout, LayerNorm

**Outputs**:
- `models/f1_vae_model_*.pth`
- `data/preprocessed/vae_latent_*.csv` (4D latent vectors)
- Training metrics & visualizations

---

### 08_latent_space_neural_net.ipynb
**Purpose**: Train neural network on VAE latent space for position prediction  
**Architecture**:
- **Input**: 4D latent vectors from VAE
- **Hidden Layers**: 64 ‚Üí 32 ‚Üí 16 neurons
- **Output**: Single value (predicted position 1-20)
- **Activation**: ReLU with Dropout (0.3)

**Training Details**:
- Loss: Mean Squared Error (MSE)
- Optimizer: Adam (lr=0.001)
- Epochs: 100-200 with early stopping
- Batch size: 32
- Metrics: R¬≤, MAE, MSE

**Outputs**:
- Trained neural network model
- Prediction accuracy plots
- Performance metrics (R¬≤, MAE, MSE)

---

### 09_bayesian_network_on_latent.ipynb
**Purpose**: Discretize positions and create probabilistic predictions using Bayesian Networks on VAE latent space  
**Key Functions**:
- **Position Categorization**: Convert continuous positions (1-20) into discrete categories:
  - **Podium** (0): Positions 1-3
  - **Points** (1): Positions 4-10
  - **Midfield** (2): Positions 11-15
  - **Backmarker** (3): Positions 16-20
- **Latent Space Discretization**: Bin 4D latent vectors into 3 levels (low, medium, high) per dimension
- **Bayesian Network Structure Learning**: Discover causal relationships between latent dimensions
- **Probabilistic Inference**: Predict position category distributions with confidence scores

**Latent Space Bayesian Network Approach**:
- Discretize 4D latent vectors ‚Üí 3 bins per dimension = 81 total combinations
- Learn BN structure to capture dependencies between latent dimensions
- Tests if VAE's learned latent space contains causal racing structure
- Provides probabilistic predictions instead of deterministic point estimates

**Bayesian Network Configuration**:
- Structure Learning: Hill Climb Search with BIC scoring
- Parameter Learning: Maximum Likelihood Estimation (MLE)
- Inference: Variable Elimination algorithm
- Evidence nodes: 4 discretized latent dimensions (latent_0_bin, latent_1_bin, latent_2_bin, latent_3_bin)
- Target node: Position category (Podium/Points/Midfield/Backmarker)

**Outputs**:
- Discretized position categories CSV
- BN structure visualization (DAG - Directed Acyclic Graph)
- Conditional Probability Tables (CPTs)
- Category prediction accuracy & confusion matrix
- Probability distributions for each prediction

---

## ü§ñ Model Details

### Variational Autoencoder (VAE)

**Architecture**:
```
Encoder: [29] ‚Üí [128, ReLU, Dropout] ‚Üí [64, ReLU, Dropout] ‚Üí [4 (Œº, œÉ¬≤)]
Decoder: [4] ‚Üí [64, ReLU, Dropout] ‚Üí [128, ReLU, Dropout] ‚Üí [29]
Position Predictor: [4] ‚Üí [64, ReLU] ‚Üí [32, ReLU] ‚Üí [1]
```

**Loss Function**:
```
Total Loss = Reconstruction Loss + Œ≤ √ó KL Divergence + Œª √ó Position Loss
```

**Hyperparameters**:
- Latent dimensions: 4
- Œ≤ (KL weight): 0.1 ‚Üí 0.3 (warmup)
- Œª (position weight): 1.5
- Learning rate: 0.001 with cosine annealing

**Key Features**:
- **Latent Space**: 4D compressed representation capturing:
  - Dimension 1: Grid position / qualifying performance
  - Dimension 2: Driver skill / experience
  - Dimension 3: Team strength / car performance
  - Dimension 4: Race context / circuit factors
- **Multi-task Learning**: Simultaneous reconstruction + position prediction
- **Regularization**: KL divergence prevents overfitting

---

### Neural Network Regressor

**Architecture**:
```
Input: [4] ‚Üí [64, ReLU, Dropout(0.3)] ‚Üí [32, ReLU, Dropout(0.3)] 
         ‚Üí [16, ReLU] ‚Üí [1, Linear]
```

**Training Configuration**:
- Loss: Mean Squared Error (MSE)
- Optimizer: Adam (lr=0.001)
- Regularization: Dropout (0.3) during training
- Early stopping: Patience=15 epochs

**Performance Metrics**:
- **R¬≤ Score**: Measures variance explained by the model
- **MAE (Mean Absolute Error)**: Average position error
- **MSE (Mean Squared Error)**: Squared error penalty

**Typical Results**:
- R¬≤ Score: 0.75-0.85
- MAE: 2-3 positions
- MSE: 8-15

---

### Position Categorization & Bayesian Networks

**Position Categories**:

The system discretizes continuous positions (1-20) into 4 meaningful categories:

| Category | Position Range | Label | Description |
|----------|---------------|-------|-------------|
| **Podium** | 1-3 | 0 | Top 3 finishers (trophy positions) |
| **Points** | 4-10 | 1 | Points-scoring positions |
| **Midfield** | 11-15 | 2 | Competitive midfield battles |
| **Backmarker** | 16-20 | 3 | Back-of-grid positions |

**Latent Space Discretization**:

Each of the 4 latent dimensions is binned into 3 levels:
- **Low (0)**: Bottom 33% (quantile-based)
- **Medium (1)**: Middle 33%
- **High (2)**: Top 33%

This creates 3‚Å¥ = 81 possible latent space combinations, which is manageable for Bayesian Network learning with 200+ samples.

**Bayesian Network Structure (Latent Space)**:

```
[Latent_0_bin] ‚îÄ‚îÄ‚îê
[Latent_1_bin] ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚Üí [Position_Category]
[Latent_2_bin] ‚îÄ‚îÄ‚î§         (Podium/Points/
[Latent_3_bin] ‚îÄ‚îÄ‚îò          Midfield/Backmarker)
```

The Bayesian Network learns the conditional dependencies between the 4 latent dimensions and the position category. Each latent dimension may capture different aspects:
- **Latent 0**: Grid position & qualifying performance
- **Latent 1**: Driver skill & experience
- **Latent 2**: Team strength & car performance  
- **Latent 3**: Race context & circuit-specific factors

**Inference Process**:
1. Provide evidence from latent space (e.g., latent_0_bin=2, latent_1_bin=1, latent_2_bin=0, latent_3_bin=1)
2. Variable Elimination computes P(Position_Category | Evidence)
3. Output probability distribution: [P(Podium), P(Points), P(Midfield), P(Backmarker)]
4. Predict category with highest probability, along with confidence score

**Advantages of Categorization**:
- **Interpretability**: Clear racing categories vs exact positions
- **Robustness**: Less sensitive to small position changes (P4 vs P5)
- **Probabilistic**: Provides confidence distributions, not just point estimates
- **Strategic**: Teams care more about "can we score points?" than exact position

---

## üìä Data Pipeline

### Feature Engineering (29 Features)

**High Importance Features** (Weight > 0.7):
1. `grid_pos` (0.95): Starting grid position
2. `quali_pos` (0.90): Qualifying position
3. `team_strength` (0.85): Team performance rating
4. `driver_skill` (0.80): Historical driver performance
5. `gap_to_pole` (0.75): Qualifying time gap to pole position

**Medium Importance Features** (Weight 0.4-0.7):
6. `pit_stops` (0.60): Number of pit stops
7. `q3_time` (0.65): Q3 qualifying time
8. `q2_time` (0.55): Q2 qualifying time
9. `driver_experience` (0.50): Years in F1
10. `year_normalized` (0.45): Temporal factor

**Supporting Features** (Weight < 0.4):
11-29. Various telemetry, tire strategy, and race context features

### Data Weighting Strategy

**Temporal Weighting**:
- 2025 (current season): 1.0x weight
- 2024: 0.9x weight
- 2023: 0.8x weight
- 2022: 0.7x weight
- Earlier years: Diminishing weights

**Circuit Similarity Weighting**:
- Same circuit: 1.0x weight
- Similar circuit type: 0.8x weight (e.g., Singapore ‚Üí Monaco for street circuits)
- Different circuit type: 0.5x weight

**Combined Weighting**:
```
Final Weight = Temporal Weight √ó Circuit Similarity Weight
```

---

## üèÅ Circuit Configuration

### Track Characteristics

Each of the 23 F1 circuits is configured with:

- **Grid Importance** (0-1): How much starting position matters
  - Monaco: 0.98 (qualifying is everything)
  - Canada: 0.5 (lots of overtaking)
  
- **Strategy Factor** (0-1): Impact of pit stop strategy
  - Canada: 0.9 (strategy-heavy)
  - Imola: 0.3 (low strategy impact)
  
- **Chaos Factor** (0-1): Unpredictability/safety car likelihood
  - Monaco: 0.8 (high incident rate)
  - Japan: 0.2 (clean races)

- **Overtaking Difficulty**: Qualitative assessment
  - Values: "easy", "medium", "hard", "very_hard", "impossible"

### Example: Singapore GP Configuration

```python
"Singapore": {
    "circuit_type": "street",
    "overtaking_difficulty": "hard",
    "grid_importance": 0.85,
    "strategy_factor": 0.7,
    "chaos_factor": 0.6,
    "drs_zones": 3,
    "total_turns": 23,
    "lap_length_km": 5.063
}
```

---

## üìà Results

### Model Performance

**VAE Latent Space Compression**:
- Reconstruction Loss: < 0.5 (after training)
- KL Divergence: Stabilized at ~2-3
- Position Prediction MAE: 2.5-3.5 positions

**Neural Network Regressor**:
- R¬≤ Score: 0.78-0.83
- MAE: 2.2-3.0 positions
- MSE: 10-14

**Bayesian Network (Position Categories)**:
- Category Accuracy: 65-75%
- Podium Prediction Accuracy: 75-85%
- Points Prediction Accuracy: 60-70%
- BIC Score: -800 to -600 (lower is better)
- Inference Speed: <0.01s per prediction

### Prediction Accuracy by Position Category

| Category | MAE | Notes |
|----------|-----|-------|
| **Podium (1-3)** | 1.8 | High accuracy for top finishers |
| **Points (4-10)** | 2.5 | Good prediction for points scorers |
| **Midfield (11-15)** | 3.2 | More variance in midfield |
| **Backmarkers (16-20)** | 2.8 | Predictable bottom positions |

### Key Insights

1. **Grid Position Dominance**: Starting position remains the strongest predictor (0.79 correlation)
2. **Team Effect**: Team strength has second-highest impact (-0.82 correlation)
3. **Circuit Matters**: Prediction accuracy varies by circuit type (street circuits harder to predict)
4. **Latent Space Quality**: 4D compression retains 85%+ of predictive information
5. **Categorical Accuracy**: 70%+ accuracy in predicting correct position category (Podium/Points/Midfield/Backmarker)
6. **Probabilistic Confidence**: Bayesian Network provides probability distributions, not just point predictions
7. **Latent Space Structure**: BN discovers meaningful relationships between latent dimensions and racing outcomes

---

## üì¶ Requirements

### Core Dependencies

```
fastf1>=3.0.0          # F1 data fetching
pandas>=2.0.0          # Data manipulation
numpy>=1.24.0          # Numerical operations
torch>=2.0.0           # Deep learning (VAE, NN)
scikit-learn>=1.3.0    # Preprocessing, metrics
matplotlib>=3.7.0      # Visualization
seaborn>=0.12.0        # Statistical plots
scipy>=1.10.0          # Scientific computing
pgmpy>=0.1.23          # Bayesian Networks
```

### Optional (for enhanced features)

```
umap-learn>=0.5.0      # Latent space visualization
plotly>=5.0.0          # Interactive plots
jupyter>=1.0.0         # Notebook environment
```

See `requirements.txt` for complete list.

---

## üõ†Ô∏è Configuration

### Customize Circuit Selection

In `config.py`:
```python
DATA_CONFIG["selected_circuit"] = "Monaco"  # Change target circuit
```

### Adjust Feature Weights

In `config.py` ‚Üí `FEATURE_WEIGHTS`:
```python
"high_importance": {
    "grid_pos": 0.95,        # Adjust weight (0-1)
    "team_strength": 0.85,
    # ...
}
```

### Modify VAE Hyperparameters

In `04_vae_OPTIMIZED.ipynb`:
```python
latent_dim = 4              # Latent space dimensions
beta = 0.3                  # KL divergence weight
pos_weight = 1.5            # Position prediction weight
learning_rate = 0.001       # Optimizer learning rate
```

---

## ü§ù Contributing

Contributions are welcome! Please follow these guidelines:

1. **Fork the repository**
2. **Create a feature branch**: `git checkout -b feature/your-feature`
3. **Commit changes**: `git commit -m "Add your feature"`
4. **Push to branch**: `git push origin feature/your-feature`
5. **Open a Pull Request**

### Areas for Contribution

- Additional circuit configurations
- New feature engineering techniques
- Alternative model architectures (Transformers, GNNs)
- Real-time prediction integration
- Web dashboard for predictions
- Model interpretability tools

---

## üìù License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## üôè Acknowledgments

- **FastF1**: For providing excellent F1 data API
- **PyTorch**: Deep learning framework
- **F1 Community**: For insights into circuit characteristics and race dynamics
- **scikit-learn**: Machine learning utilities

---

## üìû Contact

**Project Maintainer**: chaosmaster99 
**Repository**: [F1-Prediction-System-Using-VAE-and-BN](https://github.com/HXMAN76/F1-Prediction-System-Using-VAE-and-BN)  
**Issues**: [GitHub Issues](https://github.com/HXMAN76/F1-Prediction-System-Using-VAE-and-BN/issues)

---

## üîÆ Future Enhancements

- [ ] Real-time race prediction during live races
- [ ] Weather integration (rain probability impact)
- [ ] Tire degradation modeling
- [ ] Safety car probability prediction
- [ ] Driver-specific performance models
- [ ] Ensemble methods (VAE + NN + BN)
- [ ] Web API for predictions
- [ ] Interactive dashboard with live data
- [ ] Historical race replay predictions

---

## üìö Additional Resources

- [FastF1 Documentation](https://docs.fastf1.dev/)
- [VAE Tutorial](https://arxiv.org/abs/1312.6114)
- [F1 Technical Regulations](https://www.fia.com/regulation/category/110)
- [Circuit Guides](https://www.formula1.com/en/racing/2025.html)

---

**‚≠ê If you find this project useful, please consider giving it a star on GitHub!**

---

*Last Updated: October 13, 2025*
